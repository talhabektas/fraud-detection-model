# ğŸš¨ Real-Time Credit Card Fraud Detection System

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10-blue.svg" alt="Python">
  <img src="https://img.shields.io/badge/Apache_Kafka-7.5.0-red.svg" alt="Kafka">
  <img src="https://img.shields.io/badge/Apache_Spark-3.4.1-orange.svg" alt="Spark">
  <img src="https://img.shields.io/badge/MongoDB-7.0-green.svg" alt="MongoDB">
  <img src="https://img.shields.io/badge/Streamlit-1.27-ff4b4b.svg" alt="Streamlit">
  <img src="https://img.shields.io/badge/License-Educational-yellow.svg" alt="License">
</p>

<p align="center">
  <strong>End-to-End Real-Time Fraud Detection with Streaming ML Pipeline</strong>
</p>

---

## ğŸ“Š Overview

Bu proje, **Apache Kafka** ve **Apache Spark Streaming** kullanarak gerÃ§ek zamanlÄ± kredi kartÄ± dolandÄ±rÄ±cÄ±lÄ±k tespiti yapan bir veri analitik sistemidir.

**Key Highlights:**
- âš¡ Real-time transaction processing
- ğŸ¤– ML-powered fraud detection (99% accuracy)
- ğŸ“Š Live monitoring dashboard
- ğŸ³ Dockerized infrastructure
- ğŸ“ˆ Handles class imbalance with SMOTE
- ğŸ”„ End-to-end streaming pipeline

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Producer  â”‚â”€â”€â”€â”€â”€>â”‚    Kafka     â”‚â”€â”€â”€â”€â”€>â”‚ Spark Streaming â”‚â”€â”€â”€â”€â”€>â”‚   MongoDB    â”‚
â”‚ (CSV Data)  â”‚      â”‚   Broker     â”‚      â”‚   + ML Model    â”‚      â”‚  (Results)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
                                                     â–¼
                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                            â”‚   Dashboard     â”‚
                                            â”‚  (Monitoring)   â”‚
                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Architecture](#ï¸-architecture)
- [Features](#-features)
- [Tech Stack](#ï¸-tech-stack)
- [Dataset](#-dataset)
- [Performance](#-performance)
- [Quick Start](#-quick-start)
- [Documentation](#-documentation)
- [Project Structure](#-project-structure)
- [License](#-license)
- [Author](#-author)

---

## ğŸ¯ Features

- âœ… **Real-time Streaming**: Kafka ile gerÃ§ek zamanlÄ± veri akÄ±ÅŸÄ±
- âœ… **ML-Powered Detection**: Class imbalance iÃ§in SMOTE + Random Forest/XGBoost
- âœ… **Scalable Processing**: Apache Spark ile daÄŸÄ±tÄ±k veri iÅŸleme
- âœ… **Persistent Storage**: MongoDB ile sonuÃ§larÄ±n saklanmasÄ±
- âœ… **Live Monitoring**: Dashboard ile canlÄ± izleme
- âœ… **Dockerized**: TÃ¼m servisler Docker ile kolay kurulum

---

## ğŸ“ Project Structure

```
fraud/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ creditcard.csv              # Kaggle Credit Card Fraud Dataset (284K transactions)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ producer/
â”‚   â”‚   â””â”€â”€ kafka_producer.py       # CSV'den Kafka'ya veri gÃ¶nderimi
â”‚   â”œâ”€â”€ consumer/
â”‚   â”‚   â””â”€â”€ spark_consumer.py       # Spark Streaming + ML prediction
â”‚   â”œâ”€â”€ ml_model/
â”‚   â”‚   â”œâ”€â”€ train_model.py          # Model eÄŸitimi
â”‚   â”‚   â”œâ”€â”€ preprocessing.py        # Data preprocessing & SMOTE
â”‚   â”‚   â””â”€â”€ model.pkl               # Trained model (saved)
â”‚   â””â”€â”€ dashboard/
â”‚       â””â”€â”€ app.py                  # Streamlit dashboard
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ docker-compose.yml          # Kafka, Zookeeper, MongoDB
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ eda.ipynb                   # Exploratory Data Analysis
â”œâ”€â”€ requirements.txt                # Python dependencies
â””â”€â”€ README.md                       # This file
```

---

## ğŸ› ï¸ Tech Stack

### Core Capabilities
- **Real-Time Streaming**: Apache Kafka message queue with 3 partitions

- **Distributed Processing**: Apache Spark Structured Streaming```

- **ML Detection**: Random Forest classifier with SMOTE balancing

- **Persistent Storage**: MongoDB for prediction results## ğŸ› ï¸ Technologies Used

- **Live Dashboard**: Streamlit-based real-time monitoring

- **Containerized**: Docker Compose for easy deployment- **Data Streaming**: Apache Kafka 3.x

- **Stream Processing**: Apache Spark 3.x (PySpark)

### ML Pipeline- **Machine Learning**: Scikit-learn, XGBoost, Imbalanced-learn

- âœ… Feature engineering (time-based, interaction features)- **Database**: MongoDB

- âœ… StandardScaler normalization- **Visualization**: Streamlit / Matplotlib / Plotly

- âœ… SMOTE for class imbalance (0.17% â†’ 50%)- **Orchestration**: Docker & Docker Compose

- âœ… Random Forest with 100 trees- **Language**: Python 3.11+

- âœ… Real-time inference on streaming data

## ğŸ“Š Dataset

---

**Kaggle Credit Card Fraud Detection Dataset**

## ğŸ—ï¸ Architecture- **Size**: 284,807 transactions

- **Features**: 30 (Time, V1-V28 PCA, Amount, Class)

```bash
- **Target**: Class (0=Normal, 1=Fraud)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”- **Imbalance**: ~0.17% fraud (highly imbalanced)

â”‚  CSV Dataset    â”‚  284,807 transactions

â”‚  (Producer)     â”‚## ğŸš€ Quick Start

â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜

         â”‚ Kafka Streaming### 1. Prerequisites

         â–¼
```
```bash
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”# Python 3.9+

â”‚  Apache Kafka   â”‚  3 partitions# Docker & Docker Compose

â”‚  + Zookeeper    â”‚  Real-time queue# Java 11+ (for Spark)

â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜```

         â”‚ Stream consume

         â–¼
```
### 2. Setup Infrastructure
```bash
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚ Spark Streaming â”‚  Micro-batch processing# Start Kafka, Zookeeper, MongoDB

â”‚   + ML Model    â”‚  Feature engineeringcd docker

â”‚                 â”‚  Fraud predictiondocker-compose up -d

â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜

         â”‚ Save results

         â–¼
```
### 3. Install Dependencies
```bash
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚    MongoDB      â”‚â”€â”€â”€â”€â”€â–¶â”‚   Streamlit     â”‚pip install -r requirements.txt

â”‚  (Predictions)  â”‚      â”‚   Dashboard     â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4. Train ML Model

```bash

---python src/ml_model/train_model.py

```

## ğŸ› ï¸ Tech Stack

### 5. Start Producer (Stream Data)

### Data Streaming
```bash

- **Apache Kafka 7.5.0**: Distributed messaging systempython src/producer/kafka_producer.py

- **Zookeeper**: Kafka coordination service

- **Kafka-Python**: Producer client
```

### 6. Start Consumer (Process & Predict)

### Stream Processing
```bash

- **Apache Spark 3.4.1**: Distributed computing enginespark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.0 \

- **PySpark**: Python API for Spark  src/consumer/spark_consumer.py

- **Spark Structured Streaming**: Real-time data processing
```



### Machine Learning
### 7. Launch Dashboard

- **Scikit-learn 1.3.0**: ML algorithms and preprocessing```bash

- **XGBoost 2.0.0**: Gradient boosting (alternative model)streamlit run src/dashboard/app.py

- **Imbalanced-learn 0.11.0**: SMOTE implementation```

- **Joblib**: Model serialization

## ğŸ“ˆ ML Pipeline

### Storage & Database

- **MongoDB 7.0**: NoSQL database for predictions1. **Data Preprocessing**

- **PyMongo**: Python MongoDB driver   - Missing value handling

   - Feature scaling (StandardScaler)

### Visualization & Monitoring   - SMOTE for class imbalance

- **Streamlit 1.27.0**: Interactive dashboard

- **Plotly 5.17.0**: Interactive visualizations2. **Model Training**

- **Matplotlib & Seaborn**: Statistical plots   - Algorithm: Random Forest / XGBoost

   - Cross-validation: 5-fold

### DevOps & Infrastructure   - Metrics: Precision, Recall, F1-Score, ROC-AUC

- **Docker & Docker Compose**: Containerization

- **Conda**: Environment management3. **Real-time Prediction**

- **Python 3.10**: Programming language   - Spark Streaming reads from Kafka

   - Model inference on each transaction

---   - Results saved to MongoDB



## ğŸ“Š Dataset## ğŸ“Š Performance Metrics



**Source**: [Kaggle - Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)
|Metric | Score |

|--------|-------|

**Statistics**:| Accuracy | ~99% |

- **Size**: 284,807 transactions| Precision | ~95% |

- **Features**: 30 (Time, V1-V28 PCA-transformed, Amount, Class)| Recall | ~85% |

- **Target**: Class (0 = Normal, 1 = Fraud)| F1-Score | ~90% |

- **Imbalance**: 0.173% fraud cases (highly imbalanced)| ROC-AUC | ~98% |



# ğŸ“ˆ Project Performance Overview

## ğŸš€ Model Performance (Test Set)

**Codebase Summary**
- **Total Code Lines:** ~1,300+ Python LOC  
- **Files:** 13 core files  
- **Technologies:** 10+ different tech stack components  
- **Dataset Size:** 284,807 transactions  
- **Model Accuracy:** ~99%  
- **Processing Speed:** 500â€“2000 tx/s  

### ğŸ” Metrics

| Metric        | Score   |
|---------------|---------|
| **Accuracy**  | 99.97%  |
| **Precision** | 78.3%   |
| **Recall**    | 84.7%   |
| **F1-Score**  | 81.4%   |
| **ROC-AUC**   | 96.9%   |

---

## ğŸ“Š Confusion Matrix (Test Set)

|                | Predicted Negative | Predicted Positive |
|----------------|--------------------|--------------------|
| **Actual Negative** | 56,841 (TN)       | 23 (FP)            |
| **Actual Positive** | 15 (FN)           | 83 (TP)            |

---

# âš™ï¸ System Performance

- **Throughput:** 500â€“2000 tx/s  
- **Latency:** <500 ms end-to-end  
- **Model Inference Time:** ~10 ms per batch  
- **Kafka Partitions:** 3  

---


## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- Docker Desktop
- Conda (Anaconda/Miniconda)
- Java 11+ (auto-installed via Conda)

### 1. Clone Repository
```bash
git clone https://github.com/talhabektas/fraud-detection-model.git
cd fraud
```

### 2. Setup Environment
```bash
# Create conda environment
conda create -n fraud python=3.11 -y
conda activate fraud

# Install dependencies
conda install -y pandas numpy scikit-learn matplotlib seaborn openjdk=11
pip install imbalanced-learn xgboost kafka-python pyspark pymongo streamlit plotly python-dotenv tqdm joblib
```

### 3. Start Infrastructure
```bash
# Start Docker services (Kafka, Zookeeper, MongoDB)
cd docker
docker compose up -d
cd ..

# Create Kafka topic
docker exec fraud-kafka kafka-topics --create \
  --topic fraud-transactions \
  --bootstrap-server localhost:9092 \
  --replication-factor 1 \
  --partitions 3
```

### 4. Train ML Model
```bash
conda activate fraud
python src/ml_model/train_model.py
```

### 5. Run System (3 Terminals)

**Terminal 1 - Producer:**
```bash
conda activate fraud
python src/producer/kafka_producer.py --limit 500 --delay 0.5
```

**Terminal 2 - Consumer:**
```bash
conda activate fraud
export JAVA_HOME=$CONDA_PREFIX
spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.0,org.mongodb.spark:mongo-spark-connector_2.12:10.2.0 \
  src/consumer/spark_consumer.py
```

**Terminal 3 - Dashboard:**
```bash
conda activate fraud
streamlit run src/dashboard/app.py
```

### 6. Access Services

| Service | URL |
|---------|-----|
| **Dashboard** | http://localhost:8501 |
| **Spark UI** | http://localhost:4040 |
| **MongoDB Express** | http://localhost:8081  |



---

## ğŸ“ Project Structure

```
fraud-detection/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ creditcard.csv              # Dataset (284K transactions)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ producer/
â”‚   â”‚   â””â”€â”€ kafka_producer.py       # Kafka data streaming
â”‚   â”œâ”€â”€ consumer/
â”‚   â”‚   â””â”€â”€ spark_consumer.py       # Spark consumer + ML
â”‚   â”œâ”€â”€ ml_model/
â”‚   â”‚   â”œâ”€â”€ preprocessing.py        # Data preprocessing
â”‚   â”‚   â”œâ”€â”€ train_model.py          # Model training
â”‚   â”‚   â”œâ”€â”€ model.pkl              # Trained model (generated)
â”‚   â”‚   â””â”€â”€ scaler.pkl             # Fitted scaler (generated)
â”‚   â””â”€â”€ dashboard/
â”‚       â””â”€â”€ app.py                  # Streamlit dashboard
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ docker-compose.yml          # Infrastructure setup
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ eda.ipynb                   # Exploratory analysis
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ .gitignore                      # Git ignore rules
â”œâ”€â”€ README.md                       # This file

```

**Total**: ~1,300+ lines of Python code across 7 core modules.

---

## ğŸ“ Key Learnings

This project demonstrates:
- âœ… **Event-Driven Architecture**: Kafka producer-consumer pattern
- âœ… **Stream Processing**: Spark Structured Streaming with micro-batches
- âœ… **ML in Production**: Real-time model inference at scale
- âœ… **Class Imbalance**: SMOTE for handling imbalanced datasets
- âœ… **Containerization**: Docker for reproducible deployments
- âœ… **Data Pipeline**: End-to-end ETL with streaming data

---

## ğŸ“„ License

This project is created for **educational purposes** as part of a university Data Analytics course.

**Dataset License**: The Credit Card Fraud Detection dataset is provided by [Kaggle](https://www.kaggle.com/mlg-ulb/creditcardfraud).

---

## ğŸ‘¨â€ğŸ’» Author

**Mehmet Talha Bektas**
- Course: Data Analytics
- GitHub: [@mehmetalha](https://github.com/talhabektas)

---

## ğŸ™ Acknowledgments

- **Dataset**: ULB Machine Learning Group via Kaggle
- **Technologies**: Apache Software Foundation, MongoDB Inc.
- **Inspiration**: Real-world fraud detection systems
---

## â­ Star This Project

If you found this project helpful, please consider giving it a star! â­

---


<p align="center">
  Made with Apache Kafka â€¢ Spark â€¢ MongoDB â€¢ Python
</p>
